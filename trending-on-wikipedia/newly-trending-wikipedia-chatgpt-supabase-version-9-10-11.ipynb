{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending Wikipedia articles with current news context\n",
    "\n",
    "- Adding new prompt/column to get a very short news relation summary\n",
    "- Save to Supabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install openai supabase dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SERPER_API_KEY = os.environ[\"SERPER_API_KEY\"] \n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"] \n",
    "WIKIPEDIA_APP_NAME = os.environ[\"WIKIPEDIA_APP_NAME\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set date to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "date_to_query = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client\n",
    "\n",
    "supabase_url = os.environ.get('SUPABASE_URL')\n",
    "supabase_key = os.environ.get('SUPABASE_KEY')\n",
    "supabase = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latest prompt versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "current_agent_version = supabase.table('agent_versions') \\\n",
    "    .select('*') \\\n",
    "    .lte('effective_date', today) \\\n",
    "    .order('effective_date', desc=True) \\\n",
    "    .limit(1) \\\n",
    "    .execute()\n",
    "\n",
    "print(current_agent_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feed data \n",
    "\n",
    "create an account here: https://api.wikimedia.org/wiki/Special:CreateAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "language_code = 'en' # English\n",
    "headers = {\n",
    "  #'Authorization': 'Bearer YOUR_ACCESS_TOKEN',\n",
    "  'User-Agent': f\"\"\"YOUR_APP_NAME ({WIKIPEDIA_APP_NAME})\"\"\"\n",
    "}\n",
    "\n",
    "base_url = 'https://api.wikimedia.org/feed/v1/wikipedia/'\n",
    "url = base_url + language_code + '/featured/' + date_to_query.strftime('%Y/%m/%d')\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "featured_feed = response.json()\n",
    "feed_date_str = featured_feed[\"mostread\"][\"date\"].rstrip(\"Z\")\n",
    "feed_date = datetime.datetime.strptime(feed_date_str, '%Y-%m-%d')\n",
    "feed_date_long =  feed_date.strftime('%B %d, %Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build data structure with all relevant information and placeholders for LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "rank_counter = 1 \n",
    "\n",
    "for item in featured_feed['mostread']['articles']:\n",
    "    title = item['title']\n",
    "    normalized_title = item['titles']['normalized']\n",
    "    view_count = item['views']\n",
    "    link = item['content_urls']['desktop']['page']\n",
    "    extract = item['extract_html']\n",
    "    thumbnail = item.get('thumbnail', {}).get('source', None)\n",
    "    view_history = item['view_history']\n",
    "    mystery_rank = item['rank'] # Not sure why the first article is always ranked 3\n",
    "\n",
    "    article={\n",
    "        'date': feed_date_str,\n",
    "        'title': title,\n",
    "        'normalized_title': normalized_title,\n",
    "        'summary': '',\n",
    "        'view_count': view_count,\n",
    "        'rank': rank_counter,\n",
    "        'mystery_rank': mystery_rank,\n",
    "        'link': link,\n",
    "        'thumbnail': thumbnail,\n",
    "        'extract': extract,\n",
    "        'raw_text': '',\n",
    "        'trending_reason': '',\n",
    "        'view_history': view_history,\n",
    "        'is_newly_trending': '',\n",
    "        'view_delta_percentage': '',\n",
    "        'raw_news_results': '',\n",
    "        'news_relation': '',\n",
    "        'news_relation_short': '',\n",
    "        'categories': '',\n",
    "        'news_relation_json': ''\n",
    "    }\n",
    "\n",
    "    article_list.append(article)\n",
    "    rank_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine if the article is newly trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_trending_article_list = []\n",
    "\n",
    "for article in article_list:\n",
    "    view_history = article['view_history']\n",
    "\n",
    "    view_history_length = len(view_history)\n",
    "\n",
    "    yesterdays_views = view_history[view_history_length-2]['views']\n",
    "    todays_views = view_history[view_history_length-1]['views']\n",
    "\n",
    "    # Handle division by zero case\n",
    "    if yesterdays_views == 0:\n",
    "        view_delta_percentage = float('inf') if todays_views > 0 else 0\n",
    "    else:\n",
    "        view_delta_percentage = ((todays_views - yesterdays_views) / yesterdays_views) * 100\n",
    "\n",
    "    # More concise assignment using a boolean expression\n",
    "    article['is_newly_trending'] = view_delta_percentage > 100\n",
    "    article['view_delta_percentage'] = int(view_delta_percentage)\n",
    "    print(f\"{article['normalized_title']} view delta: {article['view_delta_percentage']} is newly trending: {article['is_newly_trending']}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_trending_count = sum(1 for article in article_list if article.get('is_newly_trending') == True)\n",
    "print( f\"Total trending: {len(article_list)}\")\n",
    "print( f\"Newly trending: {newly_trending_count}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get first 5000 characters of each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in article_list:\n",
    "  # Download raw text of article\n",
    "  if article.get('is_newly_trending') == True:\n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={article['title']}&action=raw\"\n",
    "    print(url)\n",
    "    \n",
    "    article_text = requests.get(url).text\n",
    "    article_text_truncated = article_text[:5000]\n",
    "    article['raw_text'] = article_text_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openAIClient = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize article contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openAIClient = OpenAI(api_key=OPENAI_API_KEY)\n",
    "step_1_prompt_text = current_agent_version.data[0][\"step_1_prompt_text\"]\n",
    "step_1_model_name = current_agent_version.data[0][\"step_1_model_name\"]\n",
    "\n",
    "\n",
    "for article in article_list:\n",
    "\n",
    "    extract = article['extract']\n",
    "    title = article['normalized_title']\n",
    "\n",
    "    print(f\"Analyzing {title}\")\n",
    "\n",
    "    summary_prompt = step_1_prompt_text.replace(\"{extract}\", extract).replace(\"{title}\", title)\n",
    "    print(summary_prompt)\n",
    "\n",
    "    openAISummary = openAIClient.chat.completions.create(\n",
    "        model=step_1_model_name,\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": summary_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=128,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    openAISummaryResponse = openAISummary.choices[0].message.content\n",
    "\n",
    "    print(f\"\"\"openAISummaryResponse: {openAISummaryResponse}\"\"\")\n",
    "\n",
    "    article['summary'] =  openAISummaryResponse\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Google News results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "url = \"https://google.serper.dev/news\"\n",
    "\n",
    "for article in article_list:\n",
    "  if article.get('is_newly_trending') == True:\n",
    "    title = article['normalized_title']\n",
    "    payload = json.dumps({\n",
    "      \"q\": title,\n",
    "      \"autocorrect\": False,\n",
    "      \"tbs\": \"qdr:w\"\n",
    "    })\n",
    "    headers = {\n",
    "      'X-API-KEY': SERPER_API_KEY,\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    article['raw_news_results'] = response.json()\n",
    "\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize news results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_miss_response = \"No relevant news found\"\n",
    "\n",
    "step_3_prompt_text = current_agent_version.data[0][\"step_3_prompt_text\"]\n",
    "step_3_model_name = current_agent_version.data[0][\"step_3_model_name\"]\n",
    "\n",
    "\n",
    "for article in article_list:\n",
    "    if article.get('is_newly_trending') == True:\n",
    "\n",
    "        title = article['normalized_title']\n",
    "        news = article['raw_news_results']['news']\n",
    "        extract = article['extract']\n",
    "\n",
    "        print(f\"Analyzing {title}\")\n",
    "        if len(news) == 0:\n",
    "            print(f\"No news results for {title}\")\n",
    "            continue\n",
    "\n",
    "        # If news is already a JSON string but needs reformatting\n",
    "        news_str = json.dumps(news, indent=2)\n",
    "        # Now use the string version in your replacement\n",
    "        news_prompt = step_3_prompt_text.replace(\"{title}\", title).replace(\"{news}\", news_str).replace(\"{extract}\", extract)\n",
    "\n",
    "        openAINewsRelation = openAIClient.chat.completions.create(\n",
    "            model=step_3_model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": news_prompt\n",
    "                }\n",
    "            ],\n",
    "            max_completion_tokens=2048\n",
    "        )\n",
    "\n",
    "        openAINewsResponse = openAINewsRelation.choices[0].message.content\n",
    "\n",
    "        print(openAINewsResponse)\n",
    "\n",
    "        article['news_relation'] =  openAINewsResponse\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_4_prompt_text = current_agent_version.data[0][\"step_4_prompt_text\"]\n",
    "step_4_model_name = current_agent_version.data[0][\"step_4_model_name\"]\n",
    "\n",
    "\n",
    "for article in article_list:\n",
    "\n",
    "    extract = article['extract']\n",
    "    news_relation = article['news_relation']\n",
    "    title = article['title']\n",
    "\n",
    "    print(f\"Analyzing {title}\")\n",
    "\n",
    "    category_prompt = step_4_prompt_text.replace(\"{extract}\", extract).replace(\"{news_relation}\", news_relation)\n",
    "\n",
    "    openAICategories = openAIClient.chat.completions.create(\n",
    "        model=step_4_model_name,\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": category_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=128,\n",
    "        top_p=1\n",
    "    )\n",
    "\n",
    "    openAICategoriesResponse = openAICategories.choices[0].message.content\n",
    "\n",
    "    print(openAICategoriesResponse)\n",
    "\n",
    "    article['categories'] =  openAICategoriesResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense News summary into one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_miss_response = \"No relevant news found\"\n",
    "\n",
    "step_5_prompt_text = current_agent_version.data[0][\"step_5_prompt_text\"]\n",
    "step_5_model_name = current_agent_version.data[0][\"step_5_model_name\"]\n",
    "\n",
    "\n",
    "for article in article_list:\n",
    "    if article.get('is_newly_trending') == True:\n",
    "        news_relation = article['news_relation']\n",
    "        extract = article['extract']\n",
    "\n",
    "        print(f\"Analyzing {article['title']}\")\n",
    "        news_str = json.dumps(news, indent=2)\n",
    "        \n",
    "        short_news_prompt = step_5_prompt_text.replace(\"{news_relation}\", news_relation).replace(\"{extract}\", extract)\n",
    "\n",
    "        openAINewsRelationShort = openAIClient.chat.completions.create(\n",
    "            model=step_5_model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": short_news_prompt\n",
    "                }\n",
    "            ],\n",
    "            max_completion_tokens=2048\n",
    "        )\n",
    "\n",
    "        openAIShortNewsResponse = openAINewsRelationShort.choices[0].message.content\n",
    "\n",
    "        print(f\"News relation short: {openAIShortNewsResponse}\")\n",
    "\n",
    "        article['news_relation_short'] =  openAIShortNewsResponse\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build HTML Page to display results for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start building the HTML\n",
    "# html_title = f\"<h1>Newly Trending on {feed_date_long}</h1>\\n\"\n",
    "# if len(article_list) > 0:\n",
    "#     html_list = \"<ol>\\n\"\n",
    "\n",
    "#     # Iterate through the data\n",
    "#     for item in article_list:\n",
    "#         title = item['normalized_title']\n",
    "#         link = item['link']\n",
    "#         view_count = item['view_count']\n",
    "        \n",
    "#         thumbnail = item['thumbnail']\n",
    "#         trending_reason = item['trending_reason']\n",
    "#         news_relation = item['news_relation']\n",
    "#         news_relation_short = item['news_relation_short']\n",
    "        \n",
    "#         extract = item['extract']\n",
    "#         summary = item['summary']\n",
    "\n",
    "#         # Handle null thumbnail\n",
    "#         if thumbnail:\n",
    "#             thumbnail_html = f'<img src=\"{thumbnail}\" alt=\"Thumbnail for {title}\"/><br>'\n",
    "#         else:\n",
    "#             thumbnail_html = ''\n",
    "        \n",
    "#         news_relation_output = f\"<strong>News related to this:</strong> {news_relation}<br><br>\"\n",
    "\n",
    "#         short_news_relation_output = f\"<strong>SHORT News related to this:</strong> {news_relation_short}<br><br>\"\n",
    "\n",
    "#         view_history_list = \"<ul>\"\n",
    "#         for view in item['view_history']:\n",
    "#             view_history_list += f\"<li><strong>{view['date'].split(\"Z\")[0]}:</strong> {view['views']:,}</li>\"\n",
    "#         view_history_list += \"</ul>\"\n",
    "\n",
    "#         # Create a list item for each entry\n",
    "#         if item['is_newly_trending'] == True:\n",
    "#             html_list += f\"\"\"\n",
    "#             <li>\n",
    "#                 <h2>\n",
    "#                 <a href=\"{link}\" target=\"_blank\">{title}</a><br>\n",
    "#                 </h2>\n",
    "#                 {thumbnail_html}\n",
    "#                 <strong>Views:</strong><br>\n",
    "#                 {view_history_list}<br><br>\n",
    "#                 <strong>view_delta_percentage: </strong> {item['view_delta_percentage']}<br>\n",
    "#                 <strong>Extract:</strong {extract}<br>\n",
    "#                 <strong>Summary:</strong> {summary}<br>\n",
    "\n",
    "#                 <h3>GPT o3 mini</h3>\n",
    "#                 <strong>Reason for Trending:</strong> {trending_reason}<br><br>\n",
    "#                 {news_relation_output}<br>\n",
    "#                 {short_news_relation_output}<br>\n",
    "#                 <strong>categories: </strong> {item['categories']}<br>\n",
    "                \n",
    "#             </li>\n",
    "#             \"\"\"\n",
    "#         else:\n",
    "#             html_list += f\"\"\"\n",
    "#             <li>\n",
    "#                 <h2>\n",
    "#                 <a href=\"{link}\" target=\"_blank\">{title}</a><br>\n",
    "#                 </h2>                \n",
    "#                 <strong>Views:</strong><br>\n",
    "#                 {view_history_list}<br><br>\n",
    "#                 <strong>view_delta_percentage: </strong> {item['view_delta_percentage']}<br>\n",
    "#                 <strong>categories: </strong> {item['categories']}<br>\n",
    "                \n",
    "#             </li>\n",
    "#             \"\"\"\n",
    "        \n",
    "\n",
    "#     # Close the HTML list\n",
    "#     html_list += \"\\n</ol>\"\n",
    "# else:\n",
    "#     html_list = \"<p>No articles are trending today.</p>\"\n",
    "# html_page = html_title + html_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display generated html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the HTML in the notebook (assuming Jupyter or similar)\n",
    "# from IPython.display import display, HTML\n",
    "# display(HTML(html_page))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_version_id = current_agent_version.data[0][\"id\"]\n",
    "for article in article_list:\n",
    "    # Insert each article\n",
    "    data = {\n",
    "        'agent_version_id': agent_version_id,\n",
    "        'trending_date': article['date'],\n",
    "        'title': article['title'],\n",
    "        'normalized_title': article['normalized_title'],\n",
    "        'link': article['link'],\n",
    "        'thumbnail': article['thumbnail'],\n",
    "        'extract': article['extract'],\n",
    "        'is_newly_trending': article['is_newly_trending'],\n",
    "        'view_delta_percentage': article['view_delta_percentage'],\n",
    "        'summary': article['summary'],\n",
    "        'view_count': article['view_count'],\n",
    "        'rank': article['rank'],\n",
    "        'mystery_rank': article['mystery_rank'],\n",
    "        'view_history': article['view_history'],\n",
    "        'trending_reason': article['trending_reason'],\n",
    "        'raw_news_results': article['raw_news_results'],\n",
    "        'news_relation': article[\"news_relation\"],\n",
    "        'news_relation_short': article[\"news_relation_short\"],\n",
    "        'categories': article[\"categories\"]\n",
    "    }\n",
    "    \n",
    "\n",
    "    try:\n",
    "        result = supabase.table('trending_articles').insert(data).execute()\n",
    "        print(f\"Inserted {article['title']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting {article['title']}: {str(e)}\")\n",
    "\n",
    "print(\"All data inserted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
